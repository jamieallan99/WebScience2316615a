{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScience.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfo_f1XRr0En",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "#https://chatbotslife.com/crawl-twitter-data-using-30-lines-of-python-code-e3fece99450e\n",
        "#code built on this\n",
        "\n",
        "consumer_key = \"dLCwlq9fnnMsC3MubxNf7Xbyh\"\n",
        "consumer_secret = \"hReDjRF6in1rNJgxVQfvAqBVLgnDHRkpki5rz2W9Dc3ZxDxM8C\"\n",
        "access_token = \"1230486587621990404-fA8Iq7eQnKR7u1Rp5HJV2tZudV6UHs\"\n",
        "access_secret = \"V1rrNebZbZ3FBeHWUnG11CyIYB5b2ww61x0qbgMcHOIS0\"\n",
        "tweetsPerQry = 100\n",
        "maxTweets = 30000\n",
        "\n",
        "tweets = pd.DataFrame()\n",
        "\n",
        "def addTweet(tweet, tweets):\n",
        "    username= tweet.user.name\n",
        "    id= tweet.id\n",
        "    date= tweet.created_at\n",
        "    text= tweet.text\n",
        "    source= tweet.source\n",
        "\n",
        "    try:\n",
        "        coordinates= tweet.coordinates.coordinates\n",
        "    except:\n",
        "        coordinates= None\n",
        "\n",
        "    try:\n",
        "        quoted_user= tweet.quoted_status.user.name\n",
        "    except:\n",
        "        quoted_user= None\n",
        "\n",
        "    try:\n",
        "        retweeted_user= tweet.retweeted_status.user.name\n",
        "        #retweet_users= find_retweeters(id, api)\n",
        "        retweet_id= tweet.retweeted_status.id\n",
        "        retweet_users= None\n",
        "    except:\n",
        "        retweet_id= None\n",
        "        retweeted_user= None\n",
        "        retweet_users= None\n",
        "    \n",
        "    place= tweet.place\n",
        "    hashtags= tweet.entities['hashtags']\n",
        "    tweet_dict= {\n",
        "        '_id':id,\n",
        "        'username':username,\n",
        "        'text':text,\n",
        "        'quoted_user':quoted_user,\n",
        "        'retweeted_user':retweeted_user,\n",
        "        'retweet_id':retweet_id,\n",
        "        'date':date,\n",
        "        'source':source,\n",
        "        'coordinates':coordinates,\n",
        "        'place':place,\n",
        "        'hashtags':hashtags,\n",
        "    }\n",
        "\n",
        "    return tweets.append(tweet_dict, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5bOHhp9WkZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "authentication = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "authentication.set_access_token(access_token, access_secret)\n",
        "api = tweepy.API(authentication, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
        "maxId = -1\n",
        "tweetCount = 0\n",
        "while tweetCount < maxTweets:\n",
        "    if(maxId <= 0):\n",
        "        newTweets = api.search(q='the',count=tweetsPerQry, result_type=\"recent\")\n",
        "    else:\n",
        "        newTweets = api.search(q='the',count=tweetsPerQry, max_id=str(maxId - 1), result_type=\"recent\")\n",
        "\n",
        "    if not newTweets:\n",
        "        print(\"Finished\")\n",
        "        break\n",
        "\t\n",
        "    for tweet in newTweets:\n",
        "        tweets = addTweet(tweet, tweets)\n",
        "\n",
        "    tweetCount += len(newTweets) \n",
        "    maxId = newTweets[-1].id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEE2Glti1bCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = list()\n",
        "with open(\"drive/My Drive/Data/Stopwords.txt\", \"r\") as f:\n",
        "  for line in f:\n",
        "    stopwords.append(line.strip())\n",
        "stopwords.append(\"rt\")\n",
        "stopwords.append(\"https\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHaAOYnd3ZGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords.append(\"co\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfWtvhfuWT_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tweets.head())\n",
        "tweets.to_json(\"drive/My Drive/Data/tweets.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHkXMZ4kpmJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.cluster import KMeans \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import os\n",
        "print(os.getcwd())\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuwwRXkPgULW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string \n",
        "\n",
        "for tweet in tweets[\"hashtags\"]:\n",
        "    print(tweet)\n",
        "    hashtags = '#'.join(tweet)\n",
        "    tweet = hashtags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq8EFvRBeQmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = pd.read_json(\"drive/My Drive/Data/tweets.json\",\"r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXT_nUTcps7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "#df = pd.read_json(\"tweets.json\",\"r\", lines=True)\n",
        "\n",
        "data = tweets[\"hashtags\"]\n",
        "\n",
        "tf_idf_vectorizor = TfidfVectorizer(stop_words = stopwords, #tokenizer = tokenize_and_stem,\n",
        "                             max_features = 10000)\n",
        "tf_idf = tf_idf_vectorizor.fit_transform(data)\n",
        "tf_idf_norm = normalize(tf_idf)\n",
        "tf_idf_array = tf_idf_norm.toarray()\n",
        "\n",
        "pd.DataFrame(tf_idf_array, columns=tf_idf_vectorizor.get_feature_names()).head()\n",
        "sklearn_pca = PCA(n_components = 2)\n",
        "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy2SFrqUBJQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_clusters = range(1, 10)\n",
        "\n",
        "kmeans = [KMeans(n_clusters=i, max_iter = 600) for i in number_clusters]\n",
        "\n",
        "score = [kmeans[i].fit(Y_sklearn).score(Y_sklearn) for i in range(len(kmeans))]\n",
        "\n",
        "plt.plot(number_clusters, score)\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDh7-f1OpvwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans(n_clusters=4, max_iter=600, algorithm = 'auto')\n",
        "fitted = kmeans.fit(Y_sklearn)\n",
        "prediction = kmeans.predict(Y_sklearn)\n",
        "centers = kmeans.cluster_centers_\n",
        "print(centers)\n",
        "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1], c=prediction, s=50, cmap='viridis')\n",
        "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J9U4xcXp0Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
        "    labels = np.unique(prediction)\n",
        "    dfs = []\n",
        "    for label in labels:\n",
        "        id_temp = np.where(prediction==label) # indices for each cluster\n",
        "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster\n",
        "        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores\n",
        "        features = tf_idf_vectorizor.get_feature_names()\n",
        "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
        "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
        "        dfs.append(df)\n",
        "    return dfs\n",
        "dfs = get_top_features_cluster(tf_idf_array, prediction, 15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyTFhv4vp1M5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[0][:15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKt8EIn2reIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[1][:15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp_d_7S2ri7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[2][:15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4-atC3-qvp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = pd.read_json(\"drive/My Drive/Data/tweets.json\",\"r\")\n",
        "users_hashtags = tweets[\"hashtags\"]\n",
        "with open(\"hashtags.csv\", \"w\") as f:\n",
        "\n",
        "    for user in users_hashtags:\n",
        "        hashtag_group = \"\"\n",
        "        if len(user)>1:\n",
        "            for i in range(1, len(user)):\n",
        "                hashtag_pair = user[i-1][\"text\"] + \", \" + user[i][\"text\"]\n",
        "                f.write(hashtag_pair + \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou6p9nsLDiKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quoted_user_pairs = find_quote_connections(tweets, user_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHQv59-X0hDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_pairs = list()\n",
        "#print(list(tweets[\"username\"].values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji7kroT4eaUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_quote_connections(tweets, user_pairs):\n",
        "    users = list(tweets[\"username\"].values)\n",
        "    quoted_users = list(tweets[\"quoted_user\"].values)\n",
        "    for i in range(len(users)-1):\n",
        "        if quoted_users[i]:\n",
        "            user_pairs.append((quoted_users[i], users[i]))\n",
        "    return user_pairs\n",
        "\n",
        "quoted_user_pairs = find_quote_connections(tweets, user_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AOcQpfg2htW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(quoted_user_pairs)\n",
        "print(len(quoted_user_pairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdSFn_PbNjUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"Paired_Users.txt\", \"w\") as f:\n",
        "    for pair in quoted_user_pairs:\n",
        "        f.write(str.format(\"{0}, {1}\\n\", pair[0], pair[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk5sMye9SB4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retweet_pairs = list()\n",
        "all_users = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFj3FiL3SSW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = pd.read_json(\"drive/My Drive/Data/tweets.json\",\"r\")\n",
        "retweet_pairs, all_users= find_retweet_connections(retweet_pairs, all_users)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnttLNatR6Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_retweet_connections(retweet_pairs, all_users):\n",
        "    users = list(tweets[\"username\"].values)\n",
        "    retweeted_users = list(tweets[\"retweeted_user\"].values)\n",
        "    for i in range(len(users)-1):\n",
        "        all_users.append(retweeted_users[i])\n",
        "        all_users.append(users[i])\n",
        "        if retweeted_users[i]:\n",
        "            retweet_pairs.append((retweeted_users[i], users[i]))\n",
        "    return retweet_pairs, all_users"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMRJEiOoUHYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"Retweet_pairs.csv\", \"w\") as f:\n",
        "    for pair in retweet_pairs:\n",
        "        f.write(str.format(\"{0}, {1}\\n\", pair[0], pair[1]))\n",
        "\n",
        "with open(\"Retweet_users.csv\", \"w\") as f:\n",
        "    i=0\n",
        "    for user in all_users:\n",
        "        line = str.format(\"{0}, {1}\\n\", user, i)\n",
        "        f.write(line)\n",
        "        i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KCN6hNj2K8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vertices = set()\n",
        "with open(\"Retweet_pairs.csv\", \"r\") as f:\n",
        "    for line in f:\n",
        "        line= line.split(sep=\",\")\n",
        "        if len(line) <3:\n",
        "            vertices.add(line[0])\n",
        "            vertices.add(line[1].strip())\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0owi01p26IW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(vertices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixV3d0qQ4Nm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIPATWFZTJ5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"Retweet_pairs.csv\", \"r\") as f:\n",
        "    for line in f:\n",
        "        line= line.split(sep=\",\")\n",
        "        if len(line) <3:\n",
        "            edges.append((line[0], line[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wemQOcU5BKsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nodes_dict = {}\n",
        "for edge in edges:\n",
        "    nodes_dict[edge[0]] = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mrh9cNqDyr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for edge in edges:\n",
        "    nodes_dict[edge[0]].append(edge[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwODvElfHGP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lookup = list()\n",
        "for node in vertices:\n",
        "    lookup.append(node)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJFBO6O_Minp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj_mat = np.zeros((len(lookup)+1, len(lookup)+1,), )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LfS4JjKGgXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adjacency_matrix = list()\n",
        "adjacency_matrix.append([0])\n",
        "for node in vertices:\n",
        "    adjacency_matrix[0].append(node)\n",
        "    adjacency_matrix.append([node])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWj9BvTBHc7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for edge in edges:\n",
        "    try:\n",
        "        i = lookup.index(edge[0])\n",
        "        j = lookup.index(edge[1])\n",
        "    except:\n",
        "        continue\n",
        "    adj_mat[i][j] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soS0KnhvBW89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(nodes_dict))\n",
        "print(len(edges))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKlEEcUyT3v2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(adj_mat)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}